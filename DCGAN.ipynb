{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, Flatten, MaxPool2D, Dense, BatchNormalization\n",
    "from keras.layers import UpSampling2D, Conv2DTranspose, Reshape\n",
    "from keras.models import Input, Model, Sequential, load_model\n",
    "from keras.layers import LeakyReLU, Activation\n",
    "from keras.datasets.mnist import load_data\n",
    "import numpy as np\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator():\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim=100, output_dim=1024))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dense(128*7*7))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Reshape((7, 7, 128), input_shape=(128*7*7,)))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2D(64, (5, 5), padding='same'))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2D(1, (5, 5), padding='same'))\n",
    "    model.add(Activation('tanh'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (5, 5), padding='same', input_shape=(28, 28, 1)))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(128, (5, 5)))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GAN(gen, dis):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(gen)\n",
    "    dis.trainable = False\n",
    "    model.add(dis)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=100, units=1024)`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "(x_train, _), (x_test, _) = load_data()\n",
    "\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "\n",
    "x_train = x_train[:, :, :, None]\n",
    "x_test = x_test[:, :, :, None]\n",
    "\n",
    "gen = generator()\n",
    "dis = discriminator()\n",
    "\n",
    "genAdvNet = GAN(gen, dis)\n",
    "\n",
    "gen.compile(loss='binary_crossentropy', optimizer='adadelta')\n",
    "genAdvNet.compile(loss='binary_crossentropy', optimizer='adadelta')\n",
    "dis.trainable = True\n",
    "dis.compile(loss='binary_crossentropy', optimizer='adadelta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.concatenate((np.ones(512), np.zeros(512)))\n",
    "z = np.ones(512)\n",
    "for epoch in range(100):\n",
    "    for i in range(60000//512):\n",
    "        \n",
    "        noise = np.random.uniform(-1, 1, size=(512, 100))\n",
    "        img = x_train[i*512:(i+1)*512]\n",
    "        \n",
    "        pred = gen.predict(noise)\n",
    "        \n",
    "        X = np.concatenate((img, pred))\n",
    "        \n",
    "        \n",
    "        d_loss = dis.train_on_batch(X, y)\n",
    "        \n",
    "        \n",
    "        dis.trainable = False\n",
    "        noise = np.random.uniform(-1, 1, size=(512, 100))\n",
    "        \n",
    "        g_loss = genAdvNet.train_on_batch(noise, z)\n",
    "        dis.trainable = True\n",
    "        \n",
    "    print(\"batch %d d_loss : %f\" % (d_loss))\n",
    "    print(\"batch %d g_loss : %f\" % (g_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
